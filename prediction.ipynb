{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weather Prediction using Machine Learning Model\n",
    "\n",
    "Utilizing NOAA's (https://www.ncdc.noaa.gov/cdo-web/search) database of past weather and climate data, we can predict the weather and temperature within a given range.\n",
    "\n",
    "This notebook focuses on the temperature in NYC from 1970 to around late 2022."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Set up__\n",
    "* Import all necessary libraries and datset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "\n",
    "weather = pd.read_csv('./lsda/data/weather.csv', index_col='DATE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Preprocessing__\n",
    "\n",
    "When initially viewing the dataset, there are many NULL values present in the columns. In order to begin working with the data, this must be cleaned first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATION    0.000000\n",
       "NAME       0.000000\n",
       "ACMH       0.501478\n",
       "ACSH       0.501426\n",
       "AWND       0.265256\n",
       "FMTM       0.475087\n",
       "PGTM       0.363872\n",
       "PRCP       0.000000\n",
       "SNOW       0.000000\n",
       "SNWD       0.000104\n",
       "TAVG       0.680406\n",
       "TMAX       0.000000\n",
       "TMIN       0.000000\n",
       "TSUN       0.998393\n",
       "WDF1       0.501685\n",
       "WDF2       0.498678\n",
       "WDF5       0.502981\n",
       "WDFG       0.734484\n",
       "WDFM       0.999948\n",
       "WESD       0.685228\n",
       "WSF1       0.501530\n",
       "WSF2       0.498678\n",
       "WSF5       0.503033\n",
       "WSFG       0.613055\n",
       "WSFM       0.999948\n",
       "WT01       0.630217\n",
       "WT02       0.935034\n",
       "WT03       0.933271\n",
       "WT04       0.982579\n",
       "WT05       0.981127\n",
       "WT06       0.990615\n",
       "WT07       0.994400\n",
       "WT08       0.796962\n",
       "WT09       0.992741\n",
       "WT11       0.999274\n",
       "WT13       0.886711\n",
       "WT14       0.954010\n",
       "WT15       0.997822\n",
       "WT16       0.658993\n",
       "WT17       0.996889\n",
       "WT18       0.939493\n",
       "WT21       0.999741\n",
       "WT22       0.997459\n",
       "WV01       0.999948\n",
       "dtype: float64"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Q: Why are there so many NULL values???\n",
    "A: This dataset was retrieved from the National Oceanic and Atmospheric Administration, a US government agency. It is plausbile that the tech for some of these sensors did not exist at the time or just simply were not installed yet.\n",
    "'''\n",
    "\n",
    "# Sum of null values of a column / total number of rows = null percent of a row\n",
    "null_percent = weather.apply(pd.isnull).sum()/weather.shape[0] \n",
    "null_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Dealing with NULL values__\n",
    "Extract the columns (`valid_columns`) by only accept columns where the `null_percent` is less than the `NULL_THRESHOLD`\n",
    "\n",
    "All of the chosen columns should have NO null values except for **SNWD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "NULL_THRESHOLD = 0.01\n",
    "\n",
    "valid_columns = weather.columns[null_percent < NULL_THRESHOLD]\n",
    "\n",
    "weather = weather[valid_columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __SNWD (Snow Depth) Fill In__\n",
    "\n",
    "Snow is something that is (or was) very common in New York so it's important to mainatin this data for predictions. However, Snow Depth does have some NULL values so we can utilize `.ffill()` to \"guess\" the snow depth.\n",
    "\n",
    "`.ffill()` = Fill NA/NaN values by propagating the last valid observation to next valid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATION    0.0\n",
       "NAME       0.0\n",
       "PRCP       0.0\n",
       "SNOW       0.0\n",
       "SNWD       0.0\n",
       "TMAX       0.0\n",
       "TMIN       0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = weather.ffill()\n",
    "\n",
    "null_percent = weather.apply(pd.isnull).sum()/weather.shape[0] \n",
    "null_percent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __Future Steps__\n",
    "\n",
    "As NOAA only allows for 1.00GB exports, requesting data for countries is impossible. Gaining access to much larger datasets with around 100GB+ in size will allow for a deeper level of training to take place."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
